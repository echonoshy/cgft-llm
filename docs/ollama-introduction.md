# å¤§æ¨¡å‹å¿«é€Ÿéƒ¨ç½²å·¥å…· Ollama ä»‹ç»

Ollama æ˜¯ä¸€ä¸ªè½»é‡çº§çš„å¤§è¯­è¨€æ¨¡å‹éƒ¨ç½²å’Œè¿è¡Œå·¥å…·ï¼Œæ”¯æŒå¤šç§å¼€æºæ¨¡å‹çš„å¿«é€Ÿéƒ¨ç½²å’Œä½¿ç”¨ã€‚

## ğŸ› ï¸ å®‰è£… Ollama

### Mac å’Œ Windows å®‰è£…
Mac å’Œ Windows å…·æœ‰æˆç†Ÿçš„ä¸€é”®å®‰è£…å·¥å…·ï¼Œå¯ç›´æ¥ä»[å®˜ç½‘](https://ollama.com)ä¸‹è½½å®‰è£…åŒ…ã€‚

### ğŸ§ åœ¨ Linux ä¸Šæ‰‹åŠ¨å®‰è£…
å°½ç®¡å®˜æ–¹æä¾›äº†ä¸€é”®å®‰è£…è„šæœ¬ `curl -fsSL https://ollama.com/install.sh | sh`ï¼Œä½†åœ¨å†…ç½‘ç¯å¢ƒæˆ–ç‰¹æ®Šé…ç½®ä¸‹ï¼Œå¯èƒ½éœ€è¦æ‰‹åŠ¨å®‰è£…ã€‚

#### 1. å¯åŠ¨ç½‘ç»œä»£ç†ï¼ˆå¦‚éœ€è¦ï¼‰
```bash
source /etc/network_turbo
```

#### 2. ä¸‹è½½å®‰è£…åŒ…
```bash
# æ–¹æ³•1ï¼šæ‰‹åŠ¨ä» GitHub releases é¡µé¢ä¸‹è½½
# https://github.com/ollama/ollama/releases

# æ–¹æ³•2ï¼šä½¿ç”¨å‘½ä»¤è¡Œä¸‹è½½ï¼ˆæ³¨æ„æ›¿æ¢ä¸ºæœ€æ–°ç‰ˆæœ¬å·ï¼‰
curl -fsSL https://github.com/ollama/ollama/releases/download/v0.1.38/ollama-linux-amd64 -o /root/autodl-tmp/apps/ollama-linux-amd64

# æˆ–è€…ä½¿ç”¨ wget
wget -O /root/autodl-tmp/apps/ollama-linux-amd64 https://github.com/ollama/ollama/releases/download/v0.1.38/ollama-linux-amd64
```

#### 3. é…ç½®å¯æ‰§è¡Œæƒé™å¹¶åˆ›å»ºè½¯é“¾æ¥
```bash
chmod +x /root/autodl-tmp/apps/ollama-linux-amd64
sudo ln -s /root/autodl-tmp/apps/ollama-linux-amd64 /usr/local/bin/ollama
```

> **è¡¥å……è¯´æ˜**ï¼šLinux äºŒè¿›åˆ¶æ–‡ä»¶å®‰è£…ä½ç½®
> - **/bin**ï¼šåŸºæœ¬å‘½ä»¤ï¼Œç³»ç»Ÿå¼•å¯¼å’Œå•ç”¨æˆ·æ¨¡å¼ä¸‹å¯ç”¨ï¼ˆå¦‚ ls, rmï¼‰
> - **/usr/bin**ï¼šæ ‡å‡†ç”¨æˆ·å‘½ä»¤ï¼Œé€šå¸¸ç”±åŒ…ç®¡ç†å™¨å®‰è£…ï¼ˆå¦‚ sed, grepï¼‰
> - **/usr/local/bin**ï¼šæœ¬åœ°å®‰è£…çš„è½¯ä»¶å’Œè„šæœ¬ï¼Œä¸ä¾èµ–ç³»ç»ŸåŒ…ç®¡ç†å™¨

#### 4. å¯åŠ¨ Ollama æœåŠ¡
```bash
ollama serve
```

## ğŸ’» ä½¿ç”¨ Ollama

### åŸºæœ¬å‘½ä»¤
```bash
ollama run llama3   # æ‹‰å–æ¨¡å‹å¹¶å¼€å§‹å¯¹è¯
ollama list         # æ˜¾ç¤ºå·²ä¸‹è½½çš„æ¨¡å‹åˆ—è¡¨
ollama rm llama3    # åˆ é™¤æŒ‡å®šæ¨¡å‹
ollama pull llama3  # ä»…ä¸‹è½½æ¨¡å‹ï¼Œä¸å¼€å§‹å¯¹è¯
```

å¯ç”¨çš„æ¨¡å‹æ¯”[å®˜æ–¹åº“](https://ollama.com/library)åˆ—å‡ºçš„æ›´å¤šï¼Œå»ºè®®æŸ¥çœ‹ Hugging Face ä¸Šç›¸åº”æ¨¡å‹çš„è¯´æ˜ï¼Œç¡®è®¤æ˜¯å¦è¢« Ollama æ”¯æŒã€‚

### ğŸ”Œ REST API è°ƒç”¨æ–¹å¼

æ›´å¤š API è¯¦æƒ…è¯·å‚è€ƒ[å®˜æ–¹ API æ–‡æ¡£](https://github.com/ollama/ollama/blob/main/docs/api.md)ã€‚

#### æµå¼è°ƒç”¨ï¼ˆé€ token è¿”å›ï¼‰
```bash
curl http://localhost:11434/api/generate -d '{
  "model": "llama3",
  "prompt": "Why is the sky blue?"
}'
```

#### éæµå¼è°ƒç”¨ï¼ˆä¸€æ¬¡æ€§è¿”å›å®Œæ•´å›ç­”ï¼‰
```bash
curl http://localhost:11434/api/generate -d '{
  "model": "llama3",
  "prompt": "Why is the sky blue?",
  "stream": false
}'
```

#### å¤šè½®å¯¹è¯ï¼ˆä¿æŒä¸Šä¸‹æ–‡ï¼‰
```bash
curl http://localhost:11434/api/chat -d '{
  "model": "llama3",
  "messages": [
    {
      "role": "user",
      "content": "why is the sky blue?"
    },
    {
      "role": "assistant",
      "content": "due to rayleigh scattering."
    },
    {
      "role": "user",
      "content": "how is that different than mie scattering?"
    }
  ],
  "stream": false
}'
```

## ğŸ“‚ åŠ è½½æœ¬åœ°æ¨¡å‹

Ollama æ”¯æŒ GGUF æ ¼å¼æ¨¡å‹ã€‚å¦‚æœæ‚¨çš„æ¨¡å‹æ˜¯å…¶ä»–æ ¼å¼ï¼Œéœ€è¦å…ˆä½¿ç”¨ llama.cpp è½¬æ¢ä¸º GGUFã€‚
**æ³¨æ„**ï¼šå¹¶éæ‰€æœ‰ GGUF æ–‡ä»¶éƒ½ä¸ Ollama å…¼å®¹ã€‚

### 1. åˆ›å»º Modelfile
```
FROM /path/to/your/model.gguf

# è®¾ç½®æ¸©åº¦å‚æ•°ï¼ˆè¶Šé«˜åˆ›é€ æ€§è¶Šå¼ºï¼Œè¶Šä½ä¸€è‡´æ€§è¶Šå¥½ï¼‰
PARAMETER temperature 1

# è®¾ç½®ç³»ç»Ÿæç¤º
SYSTEM """
You are Mario from Super Mario Bros. Answer as Mario, the assistant, only.
"""
```

### 2. åŠ è½½æ¨¡å‹
```bash
ollama create model_name -f ./Modelfile
# model_name: åœ¨ Ollama ä¸­æ˜¾ç¤ºçš„æ¨¡å‹åç§°
# ./Modelfile: Modelfile çš„è·¯å¾„ï¼ˆå¯ä»¥æ˜¯ç›¸å¯¹æˆ–ç»å¯¹è·¯å¾„ï¼‰
```

### 3. ä½¿ç”¨æ¨¡å‹
```bash
ollama run model_name
```
